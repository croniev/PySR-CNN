{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "30ed3f6e",
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/home/croniev/Code/cysec/lib/python3.9/site-packages/juliacall/__init__.py:61: UserWarning: torch was imported before juliacall. This may cause a segfault. To avoid this, import juliacall before importing torch. For updates, see https://github.com/pytorch/pytorch/issues/78829.\n  warnings.warn(\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Detected IPython. Loading juliacall extension. See https://juliapy.github.io/PythonCall.jl/stable/compat/#IPython\n"
                }
            ],
            "source": "import numpy as np\nimport pandas as pd\nfrom model import CNN\nfrom pysr import PySRRegressor\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\nimport torch"
        },
        {
            "cell_type": "markdown",
            "id": "6c31fa23",
            "metadata": {},
            "source": "### Load Model and get Kernels"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "5f007d97",
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/tmp/ipykernel_3964/3040839533.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  cnn.load_state_dict(torch.load('cnn.pt'))\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "CNN(\n  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n  (relu1): ReLU()\n  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n  (relu2): ReLU()\n  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (out): Linear(in_features=1568, out_features=10, bias=True)\n)\namount of kernels of Conv1: torch.Size([16, 1, 5, 5])\namount of kernels of Conv2: torch.Size([32, 16, 5, 5])\nkernels of first layer:\nParameter containing:\ntensor([[[[-0.2335, -0.2440, -0.9097, -1.0703, -0.8168],\n          [-0.0917,  0.0114, -0.2991, -0.3230,  0.6103],\n          [ 0.0865,  0.0287,  0.0781,  0.3111,  0.9103],\n          [ 0.0553, -0.7562, -0.8900, -0.9722, -0.9644],\n          [ 0.0107, -0.6425, -0.8105, -0.5706, -1.1133]]],\n\n\n        [[[-0.0280, -0.6446, -1.0783, -0.0510, -0.1909],\n          [-1.2921, -1.5182, -0.0516,  0.5699, -0.5167],\n          [-0.9574, -0.2885,  0.0691,  0.1755, -0.4727],\n          [-1.2423, -0.3863,  0.5111,  0.0746, -0.8479],\n          [-1.3129,  0.2300,  0.8279, -0.4460, -0.5626]]],\n\n\n        [[[ 0.5291,  0.1248,  0.2948,  0.1704, -0.1348],\n          [-1.0246,  0.1614,  0.4258,  0.0904,  0.0019],\n          [-0.5680,  0.4559,  0.0938,  0.1415,  0.0510],\n          [ 0.1021,  0.2176, -0.0204,  0.1813,  0.2024],\n          [ 0.4457,  0.3654,  0.0859, -0.0848, -0.0403]]],\n\n\n        [[[ 0.7099, -0.0518, -0.3999, -1.3199, -0.2031],\n          [ 0.3740,  0.1910, -0.3168, -0.6762,  0.4298],\n          [ 0.5073, -0.0837, -1.3188, -0.0196,  0.5805],\n          [ 0.0269, -1.0321, -0.0367,  0.0597,  0.1610],\n          [-0.8166, -0.5479,  0.0032,  0.4293, -0.1114]]],\n\n\n        [[[ 0.2957,  0.1430,  0.0766, -0.2650,  0.5334],\n          [ 0.1057, -0.6504, -0.8972, -0.5839, -0.4445],\n          [ 0.2597,  0.0572,  0.0540,  0.1157, -0.3733],\n          [ 0.3074,  0.4609,  0.4423, -0.2986, -0.2100],\n          [-0.4084, -0.1961,  0.4710,  0.2451,  0.4294]]],\n\n\n        [[[-0.2075, -0.1561,  0.2745,  0.2814, -0.6771],\n          [-1.2981, -0.1775,  0.1404,  0.5747, -0.1818],\n          [-0.5521, -0.6337, -0.1747,  0.3559,  0.3817],\n          [-0.6198, -0.8836, -0.2142,  0.1903,  0.2794],\n          [-0.1596, -0.7851,  0.1739,  0.0362,  0.1972]]],\n\n\n        [[[ 0.1360, -0.0918,  0.1104, -0.0646,  0.2103],\n          [ 0.1062,  0.3018,  0.4091,  0.5279,  0.1627],\n          [ 0.0302, -0.3303, -0.0802,  0.2925,  0.2513],\n          [-0.6473, -1.4883, -0.8111, -0.0514, -0.3394],\n          [ 0.5227, -0.2562, -0.3381, -0.7960, -0.1770]]],\n\n\n        [[[-0.3574,  0.1063,  0.2514,  0.1884, -0.4400],\n          [-0.6735, -0.4578, -0.8785, -1.0236, -1.5146],\n          [-1.4320, -1.0363, -0.8359, -0.6239, -0.6141],\n          [-0.9241, -0.3779, -0.0595,  0.0761,  0.2091],\n          [ 0.0723,  0.3981,  0.4368,  0.3846,  0.2235]]],\n\n\n        [[[-1.0633, -0.1753,  0.4940,  0.4017,  0.7569],\n          [-0.0771, -1.0514, -1.7260, -1.4314, -0.5460],\n          [-0.0308, -0.0643,  0.0095, -0.2382, -0.7718],\n          [-0.1070,  0.5910,  0.3556, -0.4146, -0.3264],\n          [-0.2768,  0.2324,  0.4141, -0.0533, -0.1740]]],\n\n\n        [[[-0.3569, -0.0474, -0.0295, -0.3177,  0.0279],\n          [-0.4427, -0.2376,  0.1075,  0.0865,  0.0894],\n          [-0.5682, -0.0398,  0.0419, -0.1239, -0.2208],\n          [-0.2371, -0.1306, -0.2446, -0.3164, -0.2015],\n          [ 0.0484, -0.4290, -0.4255, -0.3033, -0.3477]]],\n\n\n        [[[ 0.2488,  0.4134,  0.3528,  0.0210, -1.0239],\n          [-0.0268,  0.0338,  0.1708, -0.0692, -1.6336],\n          [-0.1032,  0.0310,  0.3139, -0.8555, -0.1318],\n          [ 0.0948, -0.3197, -1.3580, -0.0030, -0.1405],\n          [-1.3413, -1.7017, -0.4596, -0.2455, -0.7042]]],\n\n\n        [[[-0.2504, -0.3598, -0.1199,  0.2551, -0.5003],\n          [ 0.1365, -0.3004, -0.3045,  0.1119, -0.1684],\n          [ 0.1980, -0.0510, -0.2116,  0.0321, -0.1766],\n          [-0.1648, -0.6461, -0.5829, -0.1265,  0.0871],\n          [ 0.1124, -0.4109, -0.9819, -0.1864,  0.4388]]],\n\n\n        [[[-0.5147,  0.1186,  0.5365, -0.5049, -0.9201],\n          [-0.0189, -0.0284, -0.9864, -0.2854, -0.1827],\n          [-1.3057, -0.6926, -0.6505,  0.2068,  0.3300],\n          [-1.3735,  0.2037,  0.2468,  0.3166,  0.0710],\n          [-0.5940, -0.6309, -0.4049,  0.7009,  0.1724]]],\n\n\n        [[[ 0.3788,  0.0794, -0.4265, -0.1576,  0.0312],\n          [-0.1865, -0.9333, -0.6402,  0.2178,  0.3531],\n          [-0.3694, -0.1459,  0.6929,  0.6214,  0.2413],\n          [ 0.2096,  0.3032,  0.4789, -0.2633, -0.4940],\n          [ 0.1812, -0.2943, -0.5340, -1.2313,  0.1955]]],\n\n\n        [[[ 0.1814, -0.2550, -0.3302, -0.2672, -0.0566],\n          [-0.5218, -0.0665, -0.1889, -0.1543,  0.1820],\n          [-0.4794, -0.0881, -0.5455,  0.1927, -0.2243],\n          [-0.1688, -0.1002, -0.1748,  0.1656, -0.0872],\n          [-0.4696, -0.3445, -0.0150,  0.0150,  0.0429]]],\n\n\n        [[[-0.0110,  0.0712,  0.1751,  0.1512, -0.7895],\n          [-0.1340,  0.0589,  0.2575, -0.0446, -1.0411],\n          [-0.2241, -0.0130,  0.5968,  0.0430, -0.3906],\n          [-0.9658, -0.3102,  0.5802,  0.0912, -0.0806],\n          [-0.6764, -0.1164, -0.1150,  0.1443, -0.1137]]]], requires_grad=True)\n"
                }
            ],
            "source": "cnn = CNN()\ncnn.load_state_dict(torch.load('cnn.pt'))\nprint(cnn)\n\nfor name, param in cnn.named_parameters():\n    if name == 'conv1.weight':\n        print(f\"amount of kernels of Conv1: {param.shape}\")\n        kernels1 = param\n    if name == 'conv2.weight':\n        print(f\"amount of kernels of Conv2: {param.shape}\")\nprint(f\"kernels of first layer:\\n{kernels1}\")"
        },
        {
            "cell_type": "markdown",
            "id": "8568b1e1",
            "metadata": {},
            "source": "### Load Dataset and get results"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "77044be3",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "test_data = datasets.MNIST(root='data', train=False, transform=ToTensor(),)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=10, shuffle=True, num_workers=1)\nsamples, labels = next(iter(test_loader))\n\ncnn.eval()\nwith torch.no_grad():\n    results = cnn(samples)"
        },
        {
            "cell_type": "markdown",
            "id": "ddee10c5",
            "metadata": {},
            "source": "### Prepare Data for PySR\nExtract the 5x5 submatrices (incl. padding) from images to use them as input"
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "id": "5729dc30",
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "(7840, 5, 5)\n(16, 7840)\n"
                }
            ],
            "source": "# Take every image and split it into 5x5 submatrices => np.array.shape = (7840, 25)\n# 25 <- flattened 5x5 patch\n# 7840 <- 28 * 28 patches per image * 10 images (batch_size)\nkernel_size = 5\nX = None\nfor x in samples:\n    x = torch.nn.functional.pad(input=x[0], pad=(2, 2, 2, 2), mode=\"constant\", value=0)\n    for i, j in np.ndindex((x.size()[0] - kernel_size + 1, x.size()[1] - kernel_size + 1)):\n        slice = x[i:i + kernel_size, j:j + kernel_size]\n        if X is None:\n            # X = np.array([slice.numpy().flatten()])\n            X = np.array([slice.numpy()])\n        else:\n            # X = np.concatenate((X, [slice.numpy().flatten()]))\n            X = np.concatenate((X, [slice.numpy()]))\n\nprint(X.shape)\n\n# Get the result for every 5x5 submatrix for each kernel => np.array.shape = (16, 7840)\n# 16 <- amount of kernels in the first layer\ny = results['relu1'].numpy().transpose(1, 0, 2, 3).reshape(16, 7840)\nprint(y.shape)"
        },
        {
            "cell_type": "markdown",
            "id": "e8003b04",
            "metadata": {},
            "source": "#### Physical Features of submatrices\nMultiply Matrix with position/speed matrix so that positional data is encoded."
        },
        {
            "cell_type": "code",
            "execution_count": 66,
            "id": "4e48cdb9",
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "[[0.         1.         2.         3.         4.        ]\n [1.         1.41421356 2.23606798 3.16227766 4.12310563]\n [2.         2.23606798 2.82842712 3.60555128 4.47213595]\n [3.         3.16227766 3.60555128 4.24264069 5.        ]\n [4.         4.12310563 4.47213595 5.         5.65685425]]\n[[0.70980394 0.7372549  0.85882354 0.99607843 0.45490196]\n [0.00392157 0.00784314 0.8980392  0.8980392  0.14117648]\n [0.         0.         0.9019608  0.6        0.        ]\n [0.         0.47843137 0.827451   0.7411765  0.6156863 ]\n [0.23921569 0.9843137  0.99607843 0.99607843 0.99607843]]\n[[0.00000000e+00 7.37254918e-01 1.71764708e+00 2.98823529e+00\n  1.81960785e+00]\n [3.92156886e-03 1.10918717e-02 2.00807675e+00 2.83984937e+00\n  5.82085527e-01]\n [0.00000000e+00 0.00000000e+00 2.55113036e+00 2.16333085e+00\n  0.00000000e+00]\n [0.00000000e+00 1.51293285e+00 2.98341697e+00 3.14454552e+00\n  3.07843149e+00]\n [9.56862748e-01 4.05842946e+00 4.45459817e+00 4.98039216e+00\n  5.63467051e+00]]\n"
                }
            ],
            "source": "d = np.fromfunction(lambda i, j: np.sqrt(i**2 + j**2), (5, 5))  # Matrix with distances to top-left corner\nprint(d)\n# Xpos = np.vectorize(lambda m: m * d.flatten())(X)\nXpos = np.array([m * d for m in X])\nprint(X[300])\nprint(Xpos[300])"
        },
        {
            "cell_type": "markdown",
            "id": "25850c0c",
            "metadata": {},
            "source": "#### Sum up rows and cols  ($f(A) \\rightarrow x, A \\in \\mathbb{R}^{5 \\times 5}, x \\in \\mathbb{R}^{10}$)"
        },
        {
            "cell_type": "code",
            "execution_count": 69,
            "id": "c0d251aa",
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "(7840, 10)\n(7840, 10)\n[3.7568629 1.9490197 1.5019608 2.662745  4.211765  0.9529412 2.2078433\n 4.4823527 4.231373  2.2078433]\n"
                }
            ],
            "source": "def sums_rows_and_cols(m):\n    return np.concatenate((m.sum(axis=1), m.sum(axis=0)))\n\nXrc = np.array([sums_rows_and_cols(m) for m in X])\nprint(Xrc.shape)\nXposrc = np.array([sums_rows_and_cols(m) for m in Xpos])\nprint(Xposrc.shape)\nprint(Xrc[300])"
        },
        {
            "cell_type": "markdown",
            "id": "2d1366a2",
            "metadata": {},
            "source": "### Symbolic Regression\n#### Over all 16 Kernels"
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "id": "105122ad",
            "metadata": {
                "scrolled": false,
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2582: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n  warnings.warn(\n/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2059: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, and consider using a larger `maxsize`.\n  warnings.warn(\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Done with Kernel 0 | 0.0%\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2582: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n  warnings.warn(\n/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2059: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, and consider using a larger `maxsize`.\n  warnings.warn(\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Done with Kernel 1 | 0.0625%\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2582: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n  warnings.warn(\n/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2059: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, and consider using a larger `maxsize`.\n  warnings.warn(\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Done with Kernel 2 | 0.125%\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2582: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n  warnings.warn(\n/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2059: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, and consider using a larger `maxsize`.\n  warnings.warn(\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Done with Kernel 3 | 0.1875%\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2582: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n  warnings.warn(\n/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2059: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, and consider using a larger `maxsize`.\n  warnings.warn(\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Done with Kernel 4 | 0.25%\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2582: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n  warnings.warn(\n/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2059: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, and consider using a larger `maxsize`.\n  warnings.warn(\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Done with Kernel 5 | 0.3125%\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2582: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n  warnings.warn(\n/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2059: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, and consider using a larger `maxsize`.\n  warnings.warn(\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Done with Kernel 6 | 0.375%\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2582: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n  warnings.warn(\n/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2059: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, and consider using a larger `maxsize`.\n  warnings.warn(\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Done with Kernel 7 | 0.4375%\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2582: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n  warnings.warn(\n/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2059: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, and consider using a larger `maxsize`.\n  warnings.warn(\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Done with Kernel 8 | 0.5%\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2582: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n  warnings.warn(\n/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2059: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, and consider using a larger `maxsize`.\n  warnings.warn(\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Done with Kernel 9 | 0.5625%\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2582: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n  warnings.warn(\n/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2059: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, and consider using a larger `maxsize`.\n  warnings.warn(\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Done with Kernel 10 | 0.625%\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2582: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n  warnings.warn(\n/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2059: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, and consider using a larger `maxsize`.\n  warnings.warn(\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Done with Kernel 11 | 0.6875%\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2582: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n  warnings.warn(\n/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2059: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, and consider using a larger `maxsize`.\n  warnings.warn(\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Done with Kernel 12 | 0.75%\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2582: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n  warnings.warn(\n/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2059: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, and consider using a larger `maxsize`.\n  warnings.warn(\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Done with Kernel 13 | 0.8125%\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2582: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n  warnings.warn(\n/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2059: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, and consider using a larger `maxsize`.\n  warnings.warn(\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Done with Kernel 14 | 0.875%\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2582: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n  warnings.warn(\n/home/croniev/Code/cysec/lib/python3.9/site-packages/pysr/sr.py:2059: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, and consider using a larger `maxsize`.\n  warnings.warn(\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Done with Kernel 15 | 0.9375%\n                                                     Kernel 0  \\\ncomplexity                                                      \n0                                                 -0.75026596   \n1                                          square(-0.0374831)   \n2                                          0.00068825914 * x2   \n3                                   square(-0.027123682) * x2   \n4                                   -0.0014752903 * (x6 - x2)   \n5                     -0.0014752903 * ((x3 / 1.2241117) - x2)   \n6                    x2 * square(inv(27.069881 + square(x3)))   \n7           (cube(0.017324438) / exp(x0)) * square(square(...   \n8           (square(-0.1099104) / ((x5 - -0.6081664) + x8)...   \n9           sin(sin(square(0.010120501 / (exp(x7) + x0)) *...   \n10          sin(sin(sin((0.010120501 / (x0 + (exp(x3) / 1....   \n11          sin((square(0.010120501 / (exp(x7) + square(0....   \n12          sin(sin(square(0.010120501 / ((exp(x7) / squar...   \n\n                                                     Kernel 1  \\\ncomplexity                                                      \n0                                                    1.051897   \n1                                               cos(1.568233)   \n2                                           0.0017828431 * x7   \n3                                   square(-0.012628844 * x7)   \n4                              square(sin(-0.012628844 * x7))   \n5                             (x7 - x5) * square(0.036182765)   \n6                      square(square(0.13685632) * (x7 - x5))   \n7                square(square(cube(-0.5216692)) * (x7 - x5))   \n8            sin((cube(0.18740545) / (x5 + 0.93164545)) * x7)   \n9           sin((cube(0.18740545) / (cube(x5) + 0.93164545...   \n10          sin((cube(0.18740545) / (square(cube(x5)) + 0....   \n11          square((square(-0.16514365) / (cube(x5) - -0.9...   \n12          sin(square((square(-0.16514365) / (cube(x5) - ...   \n\n                                                     Kernel 2  \\\ncomplexity                                                      \n0                                                 -0.78046286   \n1                                              sin(3.1119869)   \n2                                            0.023064049 * x7   \n3                                    cube(x7) * 0.00020155263   \n4                           square((x7 * -0.0055579008) * x6)   \n5                         cube(sin((0.0076151695 * x6) * x7))   \n6                     sin(cube(sin(x7 * (0.008031381 * x6))))   \n7               sin(sin(sin(cube((0.0074157002 * x7) * x6))))   \n8           sin(sin(sin(square(square(0.023894843 * x7) * ...   \n9           sin(square((x7 * 0.00532211) * (x6 - (-0.30887...   \n10          cube(sin(x6 * (((x7 + cos(x5)) * -0.0054527703...   \n11          sin(square(sin(square(x6 * (((x7 + cos(x5)) * ...   \n12          sin(square(sin(square(x6 * (((x7 + (cos(x5) * ...   \n\n                                                     Kernel 3  \\\ncomplexity                                                      \n0                                                          x0   \n1                                            square(0.108256)   \n2                                    square(0.012222254 * x9)   \n3                                        square(x1 / exp(x1))   \n4                                  (x1 / exp(x1)) * 0.3619775   \n5                           square(sin(x1) / (2.051542 + x7))   \n6                   square(sin(x1) / (square(x7) + 2.051542))   \n7                   square(square(x1) / (cube(x7) + exp(x1)))   \n8              square(sin(square(x1) / (cube(x7) + exp(x1))))   \n9            square(square(x1) / (exp(x1) + square(x6 - x0)))   \n10          square(square(x1) / (exp(x1) + (square(x0 - x6...   \n11          square(square(x1) / ((exp(x1) - sin(x6)) + squ...   \n12          square(square(x1) / (square((x6 - x0) - 0.6097...   \n\n                                                     Kernel 4  \\\ncomplexity                                                      \n0                                                          x1   \n1                                            sin(0.017470982)   \n2                                           x4 * 0.0065888427   \n3                                     square(0.01968424 * x4)   \n4                                     (x3 - x1) * 0.010468228   \n5                                 sin(0.01319999 * (x3 - x1))   \n6                           sin(0.047196664 * (x7 / exp(x1)))   \n7                square(-0.17454974 * (x7 / (2.526383 + x1)))   \n8              sin(square(x7) / square(exp(x1) - -11.183491))   \n9           sin(0.061701752 * (square(x7) / (cube(x1) - -9...   \n10          sin(sin(0.061701752 * (square(x7) / (cube(x1) ...   \n11          sin(((x7 * x6) / (cube(x1) - -7.116216)) * sin...   \n12          sin(((x7 * x6) / (cube(x1) - (-7.116216 + 1.06...   \n\n                                                     Kernel 5  \\\ncomplexity                                                      \n0                                                  -0.2573121   \n1                                         square(-0.04825424)   \n2                                           0.0007279081 * x9   \n3                                    square(-0.03467745) * x8   \n4                                  sin(cube(0.10647269) * x8)   \n5                            square(-0.045085035) * (x8 - x6)   \n6            square(-0.045085035 + -0.0019410239) * (x8 - x6)   \n7           (cube(sin(0.22118834)) / cube(x5 - -1.2736397)...   \n8                                                         NaN   \n9                                                         NaN   \n10                                                        NaN   \n11                                                        NaN   \n12                                                        NaN   \n\n                                                     Kernel 6  \\\ncomplexity                                                      \n0                                                          x1   \n1                                         square(-0.21589585)   \n2                                             0.03919996 * x1   \n3                                     square(x1 * 0.06521806)   \n4                                square(x1 / (x3 + 9.266585))   \n5                        square(x1 / (square(x3) + 8.957423))   \n6               -0.016397629 + (x1 / (8.563484 + square(x3)))   \n7           (x1 / (square(x3) + 8.563484)) + cube(-0.23534...   \n8           square(sin(x1 / (7.849802 + square(x3)))) / 0....   \n9           square(sin(sin(x1 / (8.9549265 + square(x3))))...   \n10          cube(sin(x1 / ((x3 + 6.5780864) + x5))) / sin(...   \n11          square(sin(x1 / ((x4 + 7.5410447) + (x6 * x3))...   \n12          square(sin(x1 / (((x6 + cos(x6)) * x3) + 7.541...   \n\n                                                     Kernel 7  \\\ncomplexity                                                      \n0                                                   0.7584216   \n1                                         square(-0.14742446)   \n2                                            0.009704115 * x4   \n3                                    square(-0.02433717 * x4)   \n4                                     (x4 - x3) * 0.021610584   \n5                            square(-0.033468917 * (x2 - x4))   \n6                           sin((0.042454254 * x4) / exp(x2))   \n7                     sin(square(-0.04985745 * x4) / exp(x2))   \n8                 square((-0.04985745 * (x5 - x4)) / exp(x1))   \n9              sin(square(0.061476834 * (x4 - x5)) / exp(x2))   \n10          square((-0.04985745 * (x4 - (x5 + x2))) / exp(...   \n11          square((x5 - x4) * inv((exp(x1) / -0.05296955)...   \n12          square(x4 * inv((exp(x1) / -0.05296955) - exp(...   \n\n                                                     Kernel 8  \\\ncomplexity                                                      \n0                                         square(0.117761254)   \n1                                           0.0070453533 * x0   \n2                                    square(-0.07461231) * x0   \n3                               square(sin(x7) * -0.24709514)   \n4                              square((x0 - x6) * 0.03904877)   \n5                               sin(x0 / cube(x1 + 2.197532))   \n6                         sin(x0 / exp(x1 + exp(0.90991306)))   \n7                  square((x0 / (exp(x6) + x1)) * 0.15299323)   \n8             square(sin(0.20608768 * (x0 / (x1 + exp(x6)))))   \n9           square(sin(sin(0.20608768) * (x0 / (x1 + exp(x...   \n10          square(sin(0.20608768 * ((x6 - x0) / (x1 + exp...   \n11          sin(square(x0) * (0.03904877 * cube(exp((-0.22...   \n12          sin((0.03904877 * sin(cube(exp((-0.22656752 * ...   \n\n                                   Kernel 9  \\\ncomplexity                                    \n0                                        x3   \n1                       square(0.000590408)   \n2                 square(cube(0.029799858))   \n3           cube(square(cube(0.029799858)))   \n4                                       NaN   \n5                                       NaN   \n6                                       NaN   \n7                                       NaN   \n8                                       NaN   \n9                                       NaN   \n10                                      NaN   \n11                                      NaN   \n12                                      NaN   \n\n                                                    Kernel 10  \\\ncomplexity                                                      \n0                                                 0.019486165   \n1                                            x0 * 0.007427275   \n2                                      sin(0.0074257553 * x0)   \n3                                        square(x6 / exp(x6))   \n4                                         x6 / (exp(x6) + x4)   \n5                            sin((x0 / exp(x9)) * 0.12174415)   \n6                          (x0 / (exp(x9) + x4)) * 0.12174415   \n7                      sin(x0 / cube(x9 + (x4 - -1.4468628)))   \n8                 sin(sin(x0 / cube((x4 - -1.3463597) + x9)))   \n9               sin(x0 / (cube((x4 - -1.3463597) + x9) + x8))   \n10          sin(sin(x0 / (cube((x4 - -1.2960132) + x9) + x...   \n11          sin(sin(x0 / (cube((square(x4) - -1.2960132) +...   \n12          sin(sin(x0 / (cube(x9 + ((square(x4) * 0.54791...   \n\n                                Kernel 11  \\\ncomplexity                                  \n0                                      x2   \n1                     cube(-0.0003270079)   \n2                 cube(cube(0.016411994))   \n3           cube(cube(cube(0.034999542)))   \n4                                     NaN   \n5                                     NaN   \n6                                     NaN   \n7                                     NaN   \n8                                     NaN   \n9                                     NaN   \n10                                    NaN   \n11                                    NaN   \n12                                    NaN   \n\n                                                    Kernel 12  \\\ncomplexity                                                      \n0                                               cos(1.553115)   \n1                                           x9 * 0.0062809875   \n2                                      sin(0.0062809875 * x9)   \n3                                    (x9 - x1) * 0.0069788313   \n4                             square(0.030051019 * (x1 - x9))   \n5                            square(x4 / exp(x6 + 2.8740616))   \n6                      sin((0.113328144 / exp(x0 + x6)) * x8)   \n7                 sin(x8 * (0.2067321 / (exp(x0) + exp(x6))))   \n8           sin((0.113328144 / exp((x0 + x6) * 0.7194398))...   \n9           sin(((square(0.113328144) / exp(x0 + x6)) * x8...   \n10          sin(((x9 * cube(square(0.4638219))) / exp(x0 +...   \n11          sin(x8 * ((x9 * cube(square(0.4638219))) / (sq...   \n12          sin(((x9 * cube(square(0.4638219))) / exp(x0 +...   \n\n                                                    Kernel 13  \\\ncomplexity                                                      \n0                                                          x4   \n1                                          square(0.11785679)   \n2                                            0.009628713 * x2   \n3                                    square(0.030031268 * x2)   \n4                                square(sin(0.03059222 * x2))   \n5                           sin(square(sin(0.03059222 * x2)))   \n6                        square((x2 + sin(x1)) * 0.029572815)   \n7                   sin(square(0.030113896 * (x2 + sin(x1))))   \n8           square((x2 + (sin(x1) * 2.3116872)) * 0.029572...   \n9           square(sin(cos(-0.07429869 * x8)) * (x2 * 0.05...   \n10          square((1.7124281 + sin(0.27756256 * x8)) * (0...   \n11          square(sin((x2 * 0.01653062) * (sin(0.26019695...   \n12          square(sin(sin((x2 * 0.01653062) * (sin(0.2601...   \n\n                                                    Kernel 14  \\\ncomplexity                                                      \n0                                         cube(-0.0022262826)   \n1                    cube(square(-0.0022262826)) * -0.7778142   \n2           1.6191338 / (exp(cube(1.9479613 + 2.0530648)) ...   \n3                                                         NaN   \n4                                                         NaN   \n5                                                         NaN   \n6                                                         NaN   \n7                                                         NaN   \n8                                                         NaN   \n9                                                         NaN   \n10                                                        NaN   \n11                                                        NaN   \n12                                                        NaN   \n\n                                                    Kernel 15  \ncomplexity                                                     \n0                                            sin(0.008011938)  \n1                                           0.0058570113 * x7  \n2                                      cube(0.036511302 * x7)  \n3                                    0.0058570113 * (x7 - x5)  \n4                        square(cube(-0.2980901) * (x7 - x5))  \n5                              square(sin(x2 / exp(x5 + x9)))  \n6                         sin(x2 / exp(x5 + (0.916761 + x9)))  \n7                sin(x2 / (square(x9) + exp(1.2063111 + x5)))  \n8           sin(x2 / (square(x9) + exp(square(1.2063111) +...  \n9           sin(x2 / ((square(x9) - -1.9207715) + exp(1.20...  \n10          sin((x2 * (-0.2990868 - x7)) / ((x9 + exp(x5))...  \n11          sin((x2 * (sin(x1) - x7)) / ((x9 + exp(x5)) / ...  \n12          sin((x2 * (sin(x1) - x7)) / ((exp(x5 - 0.26509...  \n"
                }
            ],
            "source": "regr_functions = pd.DataFrame()\nregr_functions.index.names = ['complexity']\nfor i in range(16):\n    regr = PySRRegressor(\n        niterations=40,\n        binary_operators=[\"+\", \"*\", \"-\", \"/\"],\n        unary_operators=[\n            \"cos\",\n            \"exp\",\n            \"sin\",\n            \"square\",\n            \"cube\",\n            \"inv(x) = 1/x\",  # Julia syntax\n        ],\n        extra_sympy_mappings={\"inv\": lambda x: 1 / x},  # Sympy syntax\n        elementwise_loss=\"loss(prediction, target) = (prediction - target)^2\",  # Julia syntax\n        warm_start=False,\n        verbosity=0,\n        temp_equation_file=True,\n    )\n\n    # regr.fit(X.reshape((X.shape[0], 25)), y[i])  # Input data as is\n    # regr.fit(Xpos.reshape((Xpos.shape[0], 25)), y[i])  # Input data coded for postition\n    regr.fit(Xposrc, y[i])  # Input data coded for position and summed\n    # print(regr.equations_)\n    regr_functions.insert(loc=i, column=f'Kernel {i}', value=regr.equations_['equation'])\n    print(f\"Done with Kernel {i} | {i+1/16 * 100}%\")\n\nprint(regr_functions)"
        },
        {
            "cell_type": "code",
            "execution_count": 71,
            "id": "f5fef776",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "# regr_functions.to_csv('regression_conv1_relu1.csv')\nregr_functions.to_csv('regression_conv1_relu1_posrc.csv')"
        },
        {
            "cell_type": "markdown",
            "id": "40d68d82",
            "metadata": {},
            "source": "#### Over the first kernel multiple times (Stability check)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0cfbc074",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "regr_stability = pd.DataFrame()\nregr_stability.index.names = ['complexity']\nfor i in range(10):\n    regr = PySRRegressor(\n        niterations=40,\n        binary_operators=[\"+\", \"*\", \"-\", \"/\"],\n        unary_operators=[\n            \"cos\",\n            \"exp\",\n            \"sin\",\n            \"square\",\n            \"cube\",\n            \"inv(x) = 1/x\",  # Julia syntax\n        ],\n        extra_sympy_mappings={\"inv\": lambda x: 1 / x},  # Sympy syntax\n        elementwise_loss=\"loss(prediction, target) = (prediction - target)^2\",  # Julia syntax\n        warm_start=False,\n        verbosity=0,\n        temp_equation_file=True,\n    )\n\n    regr.fit(X, y[0])\n    # print(regr.equations_)\n    regr_stability.insert(loc=i, column=f'Iteration {i}', value=regr.equations_['equation'])\n    print(regr_stability)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "25a0c826",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "regr_stability.to_csv('stability_conv1_relu1_kernel1.csv')"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        },
        "toc": {
            "base_numbering": 1,
            "nav_menu": {},
            "number_sections": true,
            "sideBar": true,
            "skip_h1_title": false,
            "title_cell": "Table of Contents",
            "title_sidebar": "Contents",
            "toc_cell": false,
            "toc_position": {},
            "toc_section_display": true,
            "toc_window_display": false
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}